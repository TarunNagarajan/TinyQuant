# Task-Aware Selective Quantization for LLMs
Standard post-training quantization methods often degrade model performance on reasoning-heavy tasks by applying uniform compression policies. This project investigates *Task-Aware Selective Quantization* on Microsoft Phi 2 2.7B.

