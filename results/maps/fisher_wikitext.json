{
    "model.embed_tokens.weight": 1019.2640945911407,
    "model.layers.0.self_attn.q_proj.weight": 0.7363910969579592,
    "model.layers.0.self_attn.k_proj.weight": 0.8403160409070551,
    "model.layers.0.self_attn.v_proj.weight": 431.22292643785477,
    "model.layers.0.self_attn.o_proj.weight": 39.27918116748333,
    "model.layers.0.mlp.gate_proj.weight": 4.743060735054314,
    "model.layers.0.mlp.up_proj.weight": 5.0072375275194645,
    "model.layers.0.mlp.down_proj.weight": 8.6632629185915,
    "model.layers.0.input_layernorm.weight": 3.601919136941433,
    "model.layers.0.post_attention_layernorm.weight": 0.5184034205740318,
    "model.layers.1.self_attn.q_proj.weight": 0.12390638011856936,
    "model.layers.1.self_attn.k_proj.weight": 0.15496481300215237,
    "model.layers.1.self_attn.v_proj.weight": 10.659552101045847,
    "model.layers.1.self_attn.o_proj.weight": 5.299899330362678,
    "model.layers.1.mlp.gate_proj.weight": 19.274898286908865,
    "model.layers.1.mlp.up_proj.weight": 27.77047796547413,
    "model.layers.1.mlp.down_proj.weight": 18.565754652023315,
    "model.layers.1.input_layernorm.weight": 0.18803231371566653,
    "model.layers.1.post_attention_layernorm.weight": 0.026491944961890113,
    "model.layers.2.self_attn.q_proj.weight": 0.3410566452657804,
    "model.layers.2.self_attn.k_proj.weight": 0.7478930287761614,
    "model.layers.2.self_attn.v_proj.weight": 4.946968878619373,
    "model.layers.2.self_attn.o_proj.weight": 2.25459253648296,
    "model.layers.2.mlp.gate_proj.weight": 8.217587696388364,
    "model.layers.2.mlp.up_proj.weight": 14.097712878137827,
    "model.layers.2.mlp.down_proj.weight": 39.92325447499752,
    "model.layers.2.input_layernorm.weight": 0.04489202088007005,
    "model.layers.2.post_attention_layernorm.weight": 0.032023330793890636,
    "model.layers.3.self_attn.q_proj.weight": 0.45403993187937886,
    "model.layers.3.self_attn.k_proj.weight": 1.3858697430696338,
    "model.layers.3.self_attn.v_proj.weight": 4.884398101828992,
    "model.layers.3.self_attn.o_proj.weight": 2.4207426025532186,
    "model.layers.3.mlp.gate_proj.weight": 6.095195451751351,
    "model.layers.3.mlp.up_proj.weight": 12.629573434591293,
    "model.layers.3.mlp.down_proj.weight": 6.739406459033489,
    "model.layers.3.input_layernorm.weight": 0.06923531461507082,
    "model.layers.3.post_attention_layernorm.weight": 0.03329595357354265,
    "model.layers.4.self_attn.q_proj.weight": 0.37075823807390407,
    "model.layers.4.self_attn.k_proj.weight": 0.9665268789976835,
    "model.layers.4.self_attn.v_proj.weight": 3.0288544930517673,
    "model.layers.4.self_attn.o_proj.weight": 1.8393983477726579,
    "model.layers.4.mlp.gate_proj.weight": 4.582179360091686,
    "model.layers.4.mlp.up_proj.weight": 8.318178463727236,
    "model.layers.4.mlp.down_proj.weight": 5.77190853562206,
    "model.layers.4.input_layernorm.weight": 0.041036004695342854,
    "model.layers.4.post_attention_layernorm.weight": 0.0591716432973044,
    "model.layers.5.self_attn.q_proj.weight": 0.5102751345839351,
    "model.layers.5.self_attn.k_proj.weight": 1.4542744252830744,
    "model.layers.5.self_attn.v_proj.weight": 2.134756347630173,
    "model.layers.5.self_attn.o_proj.weight": 1.7467535412870347,
    "model.layers.5.mlp.gate_proj.weight": 5.612811419181526,
    "model.layers.5.mlp.up_proj.weight": 8.325674667954445,
    "model.layers.5.mlp.down_proj.weight": 4.571726743131876,
    "model.layers.5.input_layernorm.weight": 0.03849677595280809,
    "model.layers.5.post_attention_layernorm.weight": 0.02010243066615658,
    "model.layers.6.self_attn.q_proj.weight": 0.2849063298199326,
    "model.layers.6.self_attn.k_proj.weight": 0.8212751061655581,
    "model.layers.6.self_attn.v_proj.weight": 2.4648192832246423,
    "model.layers.6.self_attn.o_proj.weight": 1.02380610560067,
    "model.layers.6.mlp.gate_proj.weight": 2.895701851695776,
    "model.layers.6.mlp.up_proj.weight": 4.093727269209921,
    "model.layers.6.mlp.down_proj.weight": 3.5860872510820627,
    "model.layers.6.input_layernorm.weight": 0.017104284474044107,
    "model.layers.6.post_attention_layernorm.weight": 0.05225290035014041,
    "model.layers.7.self_attn.q_proj.weight": 0.21490415011066943,
    "model.layers.7.self_attn.k_proj.weight": 0.3913652320043184,
    "model.layers.7.self_attn.v_proj.weight": 2.1050595454871655,
    "model.layers.7.self_attn.o_proj.weight": 1.5668065128847957,
    "model.layers.7.mlp.gate_proj.weight": 2.465814024209976,
    "model.layers.7.mlp.up_proj.weight": 3.28499249368906,
    "model.layers.7.mlp.down_proj.weight": 3.1329645849764347,
    "model.layers.7.input_layernorm.weight": 0.021862848530872725,
    "model.layers.7.post_attention_layernorm.weight": 0.05174595260177739,
    "model.layers.8.self_attn.q_proj.weight": 0.2945067274267785,
    "model.layers.8.self_attn.k_proj.weight": 0.5233079303288832,
    "model.layers.8.self_attn.v_proj.weight": 1.2708322152029723,
    "model.layers.8.self_attn.o_proj.weight": 1.1750899949111044,
    "model.layers.8.mlp.gate_proj.weight": 2.1603371696546674,
    "model.layers.8.mlp.up_proj.weight": 2.880912287160754,
    "model.layers.8.mlp.down_proj.weight": 2.8436067393049598,
    "model.layers.8.input_layernorm.weight": 0.010787808845634572,
    "model.layers.8.post_attention_layernorm.weight": 0.03801842012035195,
    "model.layers.9.self_attn.q_proj.weight": 0.37914089288096875,
    "model.layers.9.self_attn.k_proj.weight": 0.8877138481475413,
    "model.layers.9.self_attn.v_proj.weight": 1.097693515010178,
    "model.layers.9.self_attn.o_proj.weight": 1.4666576264426112,
    "model.layers.9.mlp.gate_proj.weight": 1.8965466213412583,
    "model.layers.9.mlp.up_proj.weight": 2.3607404865324497,
    "model.layers.9.mlp.down_proj.weight": 2.218082696199417,
    "model.layers.9.input_layernorm.weight": 0.011531942545843776,
    "model.layers.9.post_attention_layernorm.weight": 0.03857937918655807,
    "model.layers.10.self_attn.q_proj.weight": 0.267729033366777,
    "model.layers.10.self_attn.k_proj.weight": 0.47866543382406235,
    "model.layers.10.self_attn.v_proj.weight": 1.226301551796496,
    "model.layers.10.self_attn.o_proj.weight": 1.6489258697256446,
    "model.layers.10.mlp.gate_proj.weight": 1.5682603353634477,
    "model.layers.10.mlp.up_proj.weight": 1.9798126639798284,
    "model.layers.10.mlp.down_proj.weight": 1.8746797540225089,
    "model.layers.10.input_layernorm.weight": 0.011492072413602727,
    "model.layers.10.post_attention_layernorm.weight": 0.032597912577330135,
    "model.layers.11.self_attn.q_proj.weight": 0.28964583470951766,
    "model.layers.11.self_attn.k_proj.weight": 0.5765873463824391,
    "model.layers.11.self_attn.v_proj.weight": 1.5541925276629627,
    "model.layers.11.self_attn.o_proj.weight": 1.8777658557519317,
    "model.layers.11.mlp.gate_proj.weight": 1.3603095123544335,
    "model.layers.11.mlp.up_proj.weight": 1.8298559868708253,
    "model.layers.11.mlp.down_proj.weight": 1.7998362192884088,
    "model.layers.11.input_layernorm.weight": 0.012487083200539928,
    "model.layers.11.post_attention_layernorm.weight": 0.03433900958771119,
    "model.layers.12.self_attn.q_proj.weight": 0.2693067355430685,
    "model.layers.12.self_attn.k_proj.weight": 0.36505975399632007,
    "model.layers.12.self_attn.v_proj.weight": 0.7188927489332855,
    "model.layers.12.self_attn.o_proj.weight": 0.9875833552796394,
    "model.layers.12.mlp.gate_proj.weight": 1.2094623986631632,
    "model.layers.12.mlp.up_proj.weight": 1.6351111689582467,
    "model.layers.12.mlp.down_proj.weight": 1.5236430293880403,
    "model.layers.12.input_layernorm.weight": 0.007036652268652688,
    "model.layers.12.post_attention_layernorm.weight": 0.029617082633194514,
    "model.layers.13.self_attn.q_proj.weight": 0.213180850550998,
    "model.layers.13.self_attn.k_proj.weight": 0.6335883454885334,
    "model.layers.13.self_attn.v_proj.weight": 1.1775055890902877,
    "model.layers.13.self_attn.o_proj.weight": 1.527284815441817,
    "model.layers.13.mlp.gate_proj.weight": 1.0940313949249685,
    "model.layers.13.mlp.up_proj.weight": 1.2866573664359748,
    "model.layers.13.mlp.down_proj.weight": 1.2546540356706828,
    "model.layers.13.input_layernorm.weight": 0.012859868045779876,
    "model.layers.13.post_attention_layernorm.weight": 0.030360267403011676,
    "model.layers.14.self_attn.q_proj.weight": 0.2782065302017145,
    "model.layers.14.self_attn.k_proj.weight": 0.411538468208164,
    "model.layers.14.self_attn.v_proj.weight": 1.1251445831730962,
    "model.layers.14.self_attn.o_proj.weight": 0.8193905132357031,
    "model.layers.14.mlp.gate_proj.weight": 1.0990120333153754,
    "model.layers.14.mlp.up_proj.weight": 1.4173273425549269,
    "model.layers.14.mlp.down_proj.weight": 1.1607727187220007,
    "model.layers.14.input_layernorm.weight": 0.005453094590848195,
    "model.layers.14.post_attention_layernorm.weight": 0.024883389080059715,
    "model.layers.15.self_attn.q_proj.weight": 0.18776972574414685,
    "model.layers.15.self_attn.k_proj.weight": 0.5105655625229701,
    "model.layers.15.self_attn.v_proj.weight": 1.3156017544679344,
    "model.layers.15.self_attn.o_proj.weight": 1.663023962173611,
    "model.layers.15.mlp.gate_proj.weight": 0.9302926962263882,
    "model.layers.15.mlp.up_proj.weight": 1.1864774953573942,
    "model.layers.15.mlp.down_proj.weight": 1.1079960779752582,
    "model.layers.15.input_layernorm.weight": 0.00905948205581808,
    "model.layers.15.post_attention_layernorm.weight": 0.025540378992445767,
    "model.layers.16.self_attn.q_proj.weight": 0.27470930467825383,
    "model.layers.16.self_attn.k_proj.weight": 0.29850327532039955,
    "model.layers.16.self_attn.v_proj.weight": 0.5629754675319418,
    "model.layers.16.self_attn.o_proj.weight": 0.9822078687138855,
    "model.layers.16.mlp.gate_proj.weight": 0.96943747298792,
    "model.layers.16.mlp.up_proj.weight": 1.3637061775662005,
    "model.layers.16.mlp.down_proj.weight": 1.1059389957226813,
    "model.layers.16.input_layernorm.weight": 0.005689956627975334,
    "model.layers.16.post_attention_layernorm.weight": 0.02865588768327143,
    "model.layers.17.self_attn.q_proj.weight": 0.31020740285748616,
    "model.layers.17.self_attn.k_proj.weight": 0.9146761298179626,
    "model.layers.17.self_attn.v_proj.weight": 1.0405555819161236,
    "model.layers.17.self_attn.o_proj.weight": 0.6248611276969314,
    "model.layers.17.mlp.gate_proj.weight": 0.9861456332728267,
    "model.layers.17.mlp.up_proj.weight": 1.3615967072546482,
    "model.layers.17.mlp.down_proj.weight": 1.13738523889333,
    "model.layers.17.input_layernorm.weight": 0.01285632236249512,
    "model.layers.17.post_attention_layernorm.weight": 0.018600505172798876,
    "model.layers.18.self_attn.q_proj.weight": 0.25048226781655103,
    "model.layers.18.self_attn.k_proj.weight": 0.4194945255294442,
    "model.layers.18.self_attn.v_proj.weight": 0.7827911898493767,
    "model.layers.18.self_attn.o_proj.weight": 1.0851970775984228,
    "model.layers.18.mlp.gate_proj.weight": 1.1272189456503838,
    "model.layers.18.mlp.up_proj.weight": 1.5208354024216533,
    "model.layers.18.mlp.down_proj.weight": 1.2377672675065696,
    "model.layers.18.input_layernorm.weight": 0.008825746715956484,
    "model.layers.18.post_attention_layernorm.weight": 0.023681501719693188,
    "model.layers.19.self_attn.q_proj.weight": 0.18664902076125145,
    "model.layers.19.self_attn.k_proj.weight": 0.667766927392222,
    "model.layers.19.self_attn.v_proj.weight": 1.9635170013643801,
    "model.layers.19.self_attn.o_proj.weight": 0.7074332791380584,
    "model.layers.19.mlp.gate_proj.weight": 1.3934121900238097,
    "model.layers.19.mlp.up_proj.weight": 1.8501759618520737,
    "model.layers.19.mlp.down_proj.weight": 1.7970942566171288,
    "model.layers.19.input_layernorm.weight": 0.007507166423238232,
    "model.layers.19.post_attention_layernorm.weight": 0.026818853424629197,
    "model.layers.20.self_attn.q_proj.weight": 0.2618122319690883,
    "model.layers.20.self_attn.k_proj.weight": 0.48420374176930636,
    "model.layers.20.self_attn.v_proj.weight": 0.7684032691176981,
    "model.layers.20.self_attn.o_proj.weight": 0.8298657033592463,
    "model.layers.20.mlp.gate_proj.weight": 1.1063415706157684,
    "model.layers.20.mlp.up_proj.weight": 1.3712396319024265,
    "model.layers.20.mlp.down_proj.weight": 1.4159984765574336,
    "model.layers.20.input_layernorm.weight": 0.010431816464915755,
    "model.layers.20.post_attention_layernorm.weight": 0.014998575850768248,
    "model.layers.21.self_attn.q_proj.weight": 0.2951397132128477,
    "model.layers.21.self_attn.k_proj.weight": 0.5412929740268737,
    "model.layers.21.self_attn.v_proj.weight": 0.963354330509901,
    "model.layers.21.self_attn.o_proj.weight": 0.5971963205374777,
    "model.layers.21.mlp.gate_proj.weight": 1.4780441778711975,
    "model.layers.21.mlp.up_proj.weight": 1.8693369021639228,
    "model.layers.21.mlp.down_proj.weight": 2.0619689784944057,
    "model.layers.21.input_layernorm.weight": 0.015680529053497594,
    "model.layers.21.post_attention_layernorm.weight": 0.012140924940467812,
    "model.layers.22.self_attn.q_proj.weight": 0.2345167058520019,
    "model.layers.22.self_attn.k_proj.weight": 0.5261123325908557,
    "model.layers.22.self_attn.v_proj.weight": 0.5275332488818094,
    "model.layers.22.self_attn.o_proj.weight": 0.4543386093573645,
    "model.layers.22.mlp.gate_proj.weight": 1.6507936571724713,
    "model.layers.22.mlp.up_proj.weight": 1.9015146140009165,
    "model.layers.22.mlp.down_proj.weight": 2.293075645342469,
    "model.layers.22.input_layernorm.weight": 0.0068658052950922865,
    "model.layers.22.post_attention_layernorm.weight": 0.014678091396490345,
    "model.layers.23.self_attn.q_proj.weight": 0.24330088077113032,
    "model.layers.23.self_attn.k_proj.weight": 0.44464595592580736,
    "model.layers.23.self_attn.v_proj.weight": 0.610956093412824,
    "model.layers.23.self_attn.o_proj.weight": 0.3546725808409974,
    "model.layers.23.mlp.gate_proj.weight": 1.692103881854564,
    "model.layers.23.mlp.up_proj.weight": 1.8505768333561718,
    "model.layers.23.mlp.down_proj.weight": 2.472675859928131,
    "model.layers.23.input_layernorm.weight": 0.002647619015078817,
    "model.layers.23.post_attention_layernorm.weight": 0.010247384034300921,
    "model.layers.24.self_attn.q_proj.weight": 0.195737051544711,
    "model.layers.24.self_attn.k_proj.weight": 0.35850668093189597,
    "model.layers.24.self_attn.v_proj.weight": 0.3906826733145863,
    "model.layers.24.self_attn.o_proj.weight": 0.2887255548266694,
    "model.layers.24.mlp.gate_proj.weight": 1.8183422656729817,
    "model.layers.24.mlp.up_proj.weight": 1.9890365991741419,
    "model.layers.24.mlp.down_proj.weight": 2.131552202627063,
    "model.layers.24.input_layernorm.weight": 0.004140458383517398,
    "model.layers.24.post_attention_layernorm.weight": 0.008806246103631565,
    "model.layers.25.self_attn.q_proj.weight": 0.8720999974757433,
    "model.layers.25.self_attn.k_proj.weight": 3.2955832835286856,
    "model.layers.25.self_attn.v_proj.weight": 0.5865410988917574,
    "model.layers.25.self_attn.o_proj.weight": 0.4146786700002849,
    "model.layers.25.mlp.gate_proj.weight": 2.0328399310819805,
    "model.layers.25.mlp.up_proj.weight": 1.94558345945552,
    "model.layers.25.mlp.down_proj.weight": 2.0839613513089716,
    "model.layers.25.input_layernorm.weight": 0.02449907548361807,
    "model.layers.25.post_attention_layernorm.weight": 0.0068587729165301425,
    "model.layers.26.self_attn.q_proj.weight": 0.5505090343067423,
    "model.layers.26.self_attn.k_proj.weight": 1.101429186295718,
    "model.layers.26.self_attn.v_proj.weight": 0.1842246963060461,
    "model.layers.26.self_attn.o_proj.weight": 0.4071191574912518,
    "model.layers.26.mlp.gate_proj.weight": 2.651105619966984,
    "model.layers.26.mlp.up_proj.weight": 2.59402418974787,
    "model.layers.26.mlp.down_proj.weight": 4.998219506815076,
    "model.layers.26.input_layernorm.weight": 0.003165101169997797,
    "model.layers.26.post_attention_layernorm.weight": 0.012370514676149469,
    "model.layers.27.self_attn.q_proj.weight": 1.8431057748384774,
    "model.layers.27.self_attn.k_proj.weight": 3.1310314196161926,
    "model.layers.27.self_attn.v_proj.weight": 0.4355490771122277,
    "model.layers.27.self_attn.o_proj.weight": 1.7345512290485203,
    "model.layers.27.mlp.gate_proj.weight": 5.100616085343063,
    "model.layers.27.mlp.up_proj.weight": 6.68361834064126,
    "model.layers.27.mlp.down_proj.weight": 11.71730712801218,
    "model.layers.27.input_layernorm.weight": 0.01585053960479854,
    "model.layers.27.post_attention_layernorm.weight": 0.011721679860784207,
    "model.norm.weight": 0.008693613981449744
}